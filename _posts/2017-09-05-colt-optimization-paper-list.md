---
layout: post
title: COLT2016优化相关论文列表
date: '2017-09-05 17:05:13 +0000'
categories: jekyll update
published: true
--- 
*	Jason Lee, Max Simchowitz, Benjamin Recht and Michael Jordan. Gradient Descent only Converges to Minimizers
*	Sébastien Bubeck and Ronen Eldan. Multi-scale exploration of convex functions and bandit convex optimization
*	Andrew Cotter, Maya Gupta and Jan Pfeifer. A Light Touch for Heavily Constrained SGD
*	Srinadh Bhojanapalli, Anastasios Kyrillidis and Sujay Sanghavi. Dropping Convexity for Faster Semi-definite Optimization
*	Animashree Anandkumar and Rong Ge. Efficient approaches for escaping higher order saddle points in non-convex optimization
*	Francis Bach and Vianney Perchet. Highly-Smooth Zero-th Order Online Optimization
*	Andrej Risteski. How to calculate partition functions using convex programming hierarchies: provable bounds for variational methods
*	Hongyi Zhang and Suvrit Sra. First-order Methods for Geodesically Convex Optimization
*	Peter Auer and Chao-Kai Chiang. An algorithm with nearly optimal pseudo-regret for both stochastic and adversarial bandits

